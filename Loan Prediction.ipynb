{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Delinquency Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basic packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features in the given dataset are categorical. Hence we can replace them with unique numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['source'] = train['source'].map({'X':1,'Y':2,'Z':3}) \n",
    "train['loan_purpose'] = train['loan_purpose'].map({'A23':1,'B12':2,'C86':3}) \n",
    "train[\"financial_institution\"] = train[\"financial_institution\"].map({'Browning-Hart':1,'Swanson, Newton and Miller':2,\n",
    "                                                                     'Edwards-Hoffman':3,'Martinez, Duffy and Bird':4,\n",
    "                                                                    'Miller, Mcclure and Allen':5,'Nicholson Group':6,\n",
    "                                                                    'Turner, Baldwin and Rhodes':7,'Suarez Inc':8,\n",
    "                                                                    'Cole, Brooks and Vincent':9,'Richards-Walters':10,\n",
    "                                                                    'Richards-Walters':11,'Taylor, Hunt and Rodriguez':12,\n",
    "                                                                    'Sanchez-Robinson':13,'Sanchez, Hays and Wilkerson':14,\n",
    "                                                                    'Romero, Woods and Johnson':15,'Thornton-Davis':16,\n",
    "                                                                    'Anderson-Taylor':17,'Richardson Ltd':18,\n",
    "                                                                    'Chapman-Mcmahon':19,'OTHER':20})\n",
    "test['source'] = test['source'].map({'X':1,'Y':2,'Z':3}) \n",
    "test['loan_purpose'] = test['loan_purpose'].map({'A23':1,'B12':2,'C86':3}) \n",
    "test[\"financial_institution\"] = test[\"financial_institution\"].map({'Browning-Hart':1,'Swanson, Newton and Miller':2,\n",
    "                                                                     'Edwards-Hoffman':3,'Martinez, Duffy and Bird':4,\n",
    "                                                                    'Miller, Mcclure and Allen':5,'Nicholson Group':6,\n",
    "                                                                    'Turner, Baldwin and Rhodes':7,'Suarez Inc':8,\n",
    "                                                                    'Cole, Brooks and Vincent':9,'Richards-Walters':10,\n",
    "                                                                    'Richards-Walters':11,'Taylor, Hunt and Rodriguez':12,\n",
    "                                                                    'Sanchez-Robinson':13,'Sanchez, Hays and Wilkerson':14,\n",
    "                                                                    'Romero, Woods and Johnson':15,'Thornton-Davis':16,\n",
    "                                                                    'Anderson-Taylor':17,'Richardson Ltd':18,\n",
    "                                                                    'Chapman-Mcmahon':19,'OTHER':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>source</th>\n",
       "      <th>financial_institution</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>unpaid_principal_bal</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>origination_date</th>\n",
       "      <th>first_payment_date</th>\n",
       "      <th>loan_to_value</th>\n",
       "      <th>number_of_borrowers</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>borrower_credit_score</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>insurance_percent</th>\n",
       "      <th>co-borrower_credit_score</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>m10</th>\n",
       "      <th>m11</th>\n",
       "      <th>m12</th>\n",
       "      <th>m13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268055008619</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.250</td>\n",
       "      <td>214000</td>\n",
       "      <td>360</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>05/2012</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672831657627</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.875</td>\n",
       "      <td>144000</td>\n",
       "      <td>360</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>03/2012</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>742515242108</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3.250</td>\n",
       "      <td>366000</td>\n",
       "      <td>180</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>03/2012</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601385667462</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.750</td>\n",
       "      <td>135000</td>\n",
       "      <td>360</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>04/2012</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273870029961</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.750</td>\n",
       "      <td>124000</td>\n",
       "      <td>360</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>04/2012</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_id  source  financial_institution  interest_rate  \\\n",
       "0  268055008619       3                      7          4.250   \n",
       "1  672831657627       2                      2          4.875   \n",
       "2  742515242108       3                     16          3.250   \n",
       "3  601385667462       1                     20          4.750   \n",
       "4  273870029961       1                     20          4.750   \n",
       "\n",
       "   unpaid_principal_bal  loan_term origination_date first_payment_date  \\\n",
       "0                214000        360       2012-03-01            05/2012   \n",
       "1                144000        360       2012-01-01            03/2012   \n",
       "2                366000        180       2012-01-01            03/2012   \n",
       "3                135000        360       2012-02-01            04/2012   \n",
       "4                124000        360       2012-02-01            04/2012   \n",
       "\n",
       "   loan_to_value  number_of_borrowers  debt_to_income_ratio  \\\n",
       "0             95                  1.0                  22.0   \n",
       "1             72                  1.0                  44.0   \n",
       "2             49                  1.0                  33.0   \n",
       "3             46                  2.0                  44.0   \n",
       "4             80                  1.0                  43.0   \n",
       "\n",
       "   borrower_credit_score  loan_purpose  insurance_percent  \\\n",
       "0                  694.0             3               30.0   \n",
       "1                  697.0             2                0.0   \n",
       "2                  780.0             2                0.0   \n",
       "3                  633.0             2                0.0   \n",
       "4                  681.0             3                0.0   \n",
       "\n",
       "   co-borrower_credit_score  insurance_type  m1  m2  m3  m4  m5  m6  m7  m8  \\\n",
       "0                       0.0             0.0   0   0   0   0   0   0   1   0   \n",
       "1                       0.0             0.0   0   0   0   0   0   0   0   0   \n",
       "2                       0.0             0.0   0   0   0   0   0   0   0   0   \n",
       "3                     638.0             0.0   0   0   0   0   0   0   0   0   \n",
       "4                       0.0             0.0   0   1   2   3   4   5   6   7   \n",
       "\n",
       "   m9  m10  m11  m12  m13  \n",
       "0   0    0    0    0    1  \n",
       "1   0    0    1    0    1  \n",
       "2   0    0    0    0    1  \n",
       "3   1    1    1    1    1  \n",
       "4   8    9   10   11    1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we need to test the data for multicollinearity. We first filter out the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "new_train = train.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important step to be followed in feature engineering is to remove the numerical features with high correlation values. This is done to reduce the noise produced in the model due to multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = new_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = new_train.drop(new_train[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>source</th>\n",
       "      <th>financial_institution</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>unpaid_principal_bal</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>loan_to_value</th>\n",
       "      <th>number_of_borrowers</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>borrower_credit_score</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>insurance_percent</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>m10</th>\n",
       "      <th>m11</th>\n",
       "      <th>m12</th>\n",
       "      <th>m13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268055008619</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.250</td>\n",
       "      <td>214000</td>\n",
       "      <td>360</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672831657627</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.875</td>\n",
       "      <td>144000</td>\n",
       "      <td>360</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>742515242108</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3.250</td>\n",
       "      <td>366000</td>\n",
       "      <td>180</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601385667462</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.750</td>\n",
       "      <td>135000</td>\n",
       "      <td>360</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273870029961</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.750</td>\n",
       "      <td>124000</td>\n",
       "      <td>360</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_id  source  financial_institution  interest_rate  \\\n",
       "0  268055008619       3                      7          4.250   \n",
       "1  672831657627       2                      2          4.875   \n",
       "2  742515242108       3                     16          3.250   \n",
       "3  601385667462       1                     20          4.750   \n",
       "4  273870029961       1                     20          4.750   \n",
       "\n",
       "   unpaid_principal_bal  loan_term  loan_to_value  number_of_borrowers  \\\n",
       "0                214000        360             95                  1.0   \n",
       "1                144000        360             72                  1.0   \n",
       "2                366000        180             49                  1.0   \n",
       "3                135000        360             46                  2.0   \n",
       "4                124000        360             80                  1.0   \n",
       "\n",
       "   debt_to_income_ratio  borrower_credit_score  loan_purpose  \\\n",
       "0                  22.0                  694.0             3   \n",
       "1                  44.0                  697.0             2   \n",
       "2                  33.0                  780.0             2   \n",
       "3                  44.0                  633.0             2   \n",
       "4                  43.0                  681.0             3   \n",
       "\n",
       "   insurance_percent  insurance_type  m1  m2  m3  m4  m5  m6  m7  m8  m9  m10  \\\n",
       "0               30.0             0.0   0   0   0   0   0   0   1   0   0    0   \n",
       "1                0.0             0.0   0   0   0   0   0   0   0   0   0    0   \n",
       "2                0.0             0.0   0   0   0   0   0   0   0   0   0    0   \n",
       "3                0.0             0.0   0   0   0   0   0   0   0   0   1    1   \n",
       "4                0.0             0.0   0   1   2   3   4   5   6   7   8    9   \n",
       "\n",
       "   m11  m12  m13  \n",
       "0    0    0    1  \n",
       "1    1    0    1  \n",
       "2    0    0    1  \n",
       "3    1    1    1  \n",
       "4   10   11    1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    115422\n",
       "1       636\n",
       "Name: m13, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.m13.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above that the data is highly unbalanced. Here there are two ways in which we can resample the dataset. We either under sample the class with the higher count or we over sample the class with the lower count. oversampling of the minor class might add lot of noise to the data while undersampling the major class might remove most the data. A better way in this case is to do both oversampling of minor class and undersampling of major class by a factor of 3 or 4 to get better accuracy while modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32000\n",
       "1     2500\n",
       "Name: m13, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from math import ceil,floor\n",
    "df_major = new_train[new_train.m13 == 0]\n",
    "df_minor = new_train[new_train.m13 == 1]\n",
    "major_count = len(df_major)\n",
    "minor_count = len(df_minor)\n",
    "df_major_downsampled = resample(df_major, replace = True, n_samples = floor(major_count/(3.6*100))*100, random_state = 2018)\n",
    "df_minor_upsampled = resample(df_minor, replace = True, n_samples = floor((minor_count*4)/100)*100, random_state = 2018)\n",
    "final_sample = pd.concat([df_major_downsampled, df_minor_upsampled])\n",
    "final_sample.m13.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Train data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = final_sample.drop('m13', axis = 1)\n",
    "Y = final_sample.m13\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "#xtrain, ytrain = sm.fit_sample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Important step of feature Engineering is to scale the data inorder to normalize it and speed up the algorithm. Choosing the right scalar method also makes a significant difference interms of accuracy. Here we use the Robust Scalar as the values are not influenced by large outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "mms = RobustScaler()\n",
    "mms.fit(xtrain)\n",
    "xtrain_scaled = mms.transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score,classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score, roc_auc_score, f1_score\n",
    "def evaluate_model(ytest, ypred, ypred_proba = None):\n",
    "    if ypred_proba is not None:\n",
    "        print('ROC-AUC score of the model:   {}'.format(roc_auc_score(ytest, ypred_proba[:, 1])))\n",
    "    print('Accuracy of the model: {}\\n'.format(accuracy_score(ytest, ypred)))\n",
    "    print('Classification report: \\n{}\\n'.format(classification_report(ytest, ypred)))\n",
    "    print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(ytest, ypred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def random_forest(xtrain, xtest, ytrain):\n",
    "    rf_params = {\n",
    "        'n_estimators': 126, \n",
    "        'max_depth': 14\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    rfpred = rf.predict(xtest)\n",
    "    rfpred_proba = rf.predict_proba(xtest)\n",
    "    \n",
    "    return rfpred, rfpred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms.fit(xtest)\n",
    "xtest_scaled = mms.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred, rfpred_proba = random_forest(xtrain_scaled, xtest_scaled, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model:   0.9612532981677651\n",
      "Accuracy of the model: 0.9706280193236715\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      4802\n",
      "           1       0.96      0.62      0.75       373\n",
      "\n",
      "    accuracy                           0.97      5175\n",
      "   macro avg       0.97      0.81      0.87      5175\n",
      "weighted avg       0.97      0.97      0.97      5175\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[4793    9]\n",
      " [ 143  230]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ytest, rfpred, rfpred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbg_params = {\n",
    "    'n_estimators': 8000,\n",
    "    'max_depth': 100,\n",
    "    'objective': 'binary',\n",
    "    'learning_rate' : 0.02,\n",
    "    'num_leaves' : 250,\n",
    "    'feature_fraction': 0.64, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq': 1,\n",
    "    'boosting_type' : 'gbdt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = lightgbm.LGBMClassifier(**lbg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.64,\n",
       "               importance_type='split', learning_rate=0.02, max_depth=100,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=8000, n_jobs=-1, num_leaves=250, objective='binary',\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(xtrain_scaled, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = lgb.predict(xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred_proba = lgb.predict_proba(xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model:   0.9962498869438895\n",
      "Accuracy of the model: 0.9885990338164251\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4802\n",
      "           1       0.98      0.86      0.92       373\n",
      "\n",
      "    accuracy                           0.99      5175\n",
      "   macro avg       0.99      0.93      0.95      5175\n",
      "weighted avg       0.99      0.99      0.99      5175\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[4797    5]\n",
      " [  54  319]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ytest, lgb_pred, lgb_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy and ROC-AUC score of the LightGBM model is much better than the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the model on unseen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms.fit(new_test)\n",
    "new_test_scaled = mms.transform(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = lgb.predict(new_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_test[\"m13\"] = lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = new_test[[\"loan_id\",\"m13\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35717\n",
       "1      149\n",
       "Name: m13, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[\"m13\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
